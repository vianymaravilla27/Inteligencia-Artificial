{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbbb27c",
   "metadata": {},
   "source": [
    "**Practice 2 Cross Validation**\n",
    "\n",
    "**Vianey Maravilla Pérez**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Use the datasetweatherAUS.csv to do the following:\n",
    "\n",
    "1) Load the dataseten a pandas dataframe.\n",
    "\n",
    "2) Separate the dataset into a training (80%) and test (20%) set without mixing data.\n",
    "\n",
    "3) Using the training set create the following validation sets through cross-validation: \n",
    "  - 3 folds\n",
    "  - 5 folds\n",
    "  - 10 folds\n",
    "  \n",
    "  \n",
    "4) Create the necessary classes to store the created datasets.\n",
    "\n",
    "5) Save in csv files the data and tags of each validation set:\n",
    "  - data_validation_train_<num_pliegues>_< pliegue >.csv\n",
    "  - target_validation_train_<num_pliegues>_< pliegue >.csv\n",
    "  - data_test_<num_pliegues>_< pliegue >.csv\n",
    "  - target_test_<num_pliegues>_< pliegue >.csv\n",
    "\n",
    "6) Save the test set data and tags in csv files: \n",
    "  - data_test.csv\n",
    "  - target_test.csv\n",
    "    \n",
    "\n",
    "7) Save the object storing the created data sets in a pkl file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d32189",
   "metadata": {},
   "source": [
    "**Práctica 2 Validación cruzada**\n",
    "\n",
    "**Vianey Maravilla Pérez\n",
    "\n",
    "**Descripción:**\n",
    "\n",
    "Utilice el dataset weatherAUS.csv para realizar lo siguiente:\n",
    "\n",
    "1) Cargue el dataset en un dataframe de pandas\n",
    "\n",
    "2) Separe el dataset en un conjunto de entrenamiento (80%) y de prueba (20%%) asegurándose de mezclar los datos\n",
    "\n",
    "3) Usando el conjunto de entrenamiento cree los siguientes conjuntos de validación mediante validación cruzada:\n",
    "- 3 pliegues\n",
    "- 5 pliegues\n",
    "- 10 pliegues\n",
    "\n",
    "4) Cree las clases necesarias para almacenar los conjuntos de datos creados.\n",
    "\n",
    "5) Guarde en archivos csv los datos y etiquetas de cada conjunto de validación:\n",
    "- data_validation_train_<num_pliegues>_< pliegue >.csv\n",
    "- target_validation_train_<num_pliegues>_< pliegue >.csv\n",
    "- data_test_<num_pliegues>_< pliegue >.csv\n",
    "- target_test_<num_pliegues>_< pliegue >.csv\n",
    "\n",
    "6) Guarde en archivos csv los datos y etiquetas del conjunto de prueba \n",
    "\n",
    "- data_test.csv\n",
    "- target_test.csv\n",
    "\n",
    "7) Guarde en un archivo pkl el objeto que almacena los conjuntos de datos creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17110c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries necessary for the realization of the practice.\n",
    "# Importar las librerias necesarias para la realización de la practica.\n",
    "\n",
    "import pandas as pnd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5022d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign functions to the data\n",
    "# Asignamos funciones a los datos\n",
    "\n",
    "class data_validation:\n",
    "    def __init__(self, x_e, y_e, x_p, y_p):\n",
    "        self.x_e = x_e\n",
    "        self.y_e = y_e\n",
    "        self.x_p = x_p\n",
    "        self.y_p = y_p\n",
    "\n",
    "class test_data:\n",
    "    def __init__(self, x_p, y_p):\n",
    "        self.x_p = x_p\n",
    "        self.y_p = y_p\n",
    "\n",
    "class dataset:\n",
    "    def __init__(self, data_validation, test_data):\n",
    "        self.data_validation = data_validation\n",
    "        self.test_data = test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7048da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions created in order to create and save our different data in csv files\n",
    "# Funciones creadas con el fin de crear y guardar nuestros distintos datos en csv\n",
    "\n",
    "def savecsv(file, data, col, list_opt = False):\n",
    "    newdataset = data.tolist()\n",
    "\n",
    "    with open(file, 'w', newline='') as f:\n",
    "        if list_opt:\n",
    "            newdataset2 = [[i] for i in newdataset]\n",
    "        else:\n",
    "            newdataset2 = new_data\n",
    "        \n",
    "        write = csv.writer(f)\n",
    "        write.writerow(col)\n",
    "        write.writerows(newdataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a434dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that obtains the training data set and the test data set\n",
    "# Función que obtiene el conjunto de datos de entrenamiento y el conjunto de datos de prueba\n",
    "\n",
    "def train_data(file, tag):\n",
    "    datafram = pnd.read_csv(file, sep = ',', engine = 'python')\n",
    "    x = datafram.drop(tag, axis = 1).values\n",
    "    y = datafram[tag].values\n",
    "    \n",
    "    columns = list(datafram.columns.values)\n",
    "    columns_s = ','.join([column for column in columns if column != tag])\n",
    "    \n",
    "    x_e, x_p, y_e, y_p = train_test_split(x, y, test_size=0.2, shuffle = True)\n",
    "    x_col = columns_s\n",
    "    y_col = tag\n",
    "    return [x_e, y_e, x_p, y_p, x_col, y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec714125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cross validation\n",
    "# Función para la validación cruzada\n",
    "\n",
    "def cross_validation(data, k):\n",
    "    x_e = data[0]\n",
    "    y_e = data[1]\n",
    "    x_p = data[2]\n",
    "    y_p = data[3]\n",
    "    x_col = data[4]\n",
    "    y_col = data[5]\n",
    "    \n",
    "    print('Cross Validation k =', k)\n",
    "    data_validations = []\n",
    "    K_F = KFold(n_splits = k)\n",
    "    c = 0\n",
    "    for index_e, index_p in K_F.split(x_e):\n",
    "        c = c + 1\n",
    "        x_e_v, x_p_v = x_e[index_e], x_e[index_p]\n",
    "        y_e_v, y_p_v = y_e[index_e], y_e[index_p]\n",
    "        data_validations.append(data_validation(x_e_v, y_p_v, x_p_v, y_p_v))\n",
    "        \n",
    "        savecsv(file_name = \"./data/data_validation_train_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = x_e_v, col = x_col)\n",
    "        \n",
    "        savecsv(file_name = \"./data/target_validation_train_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = y_e_v, col = y_col, listopc = True)\n",
    "        \n",
    "        savecsv(file_name = \"./data/data_test_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = x_p_v, col = x_col)\n",
    "        \n",
    "        savecsv(file_name = \"./data/target_test_\" + str(k) + \"_\" + str(c) + \".csv\", \n",
    "                    data = y_p_v, col = y_col, listopc = True) \n",
    "    \n",
    "    test_d = test_data(x_p, y_p)\n",
    "    data_set = dataset(data_validation, test_d)\n",
    "    \n",
    "    return (data_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6cb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and test dataset\n",
    "# Conjunto de datos de entranamiento y de prueba\n",
    "\n",
    "data = train_data('./weatherAUS.csv', 'RainTomorrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdcdaa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation k = 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "savecsv() got an unexpected keyword argument 'file_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m kp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m kp:\n\u001b[1;32m----> 5\u001b[0m     datas \u001b[38;5;241m=\u001b[39m \u001b[43mcrossvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Save dataset in pickle\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     dataset_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/dataset_f\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mcrossvalidation\u001b[1;34m(data, k)\u001b[0m\n\u001b[0;32m     19\u001b[0m y_e_v, y_p_v \u001b[38;5;241m=\u001b[39m y_e[index_e], y_e[index_p]\n\u001b[0;32m     20\u001b[0m data_validations\u001b[38;5;241m.\u001b[39mappend(data_validation(x_e_v, y_p_v, x_p_v, y_p_v))\n\u001b[1;32m---> 22\u001b[0m \u001b[43msavecsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/data_validation_train_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_e_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m savecsv(file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/target_validation_train_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     26\u001b[0m             data \u001b[38;5;241m=\u001b[39m y_e_v, col \u001b[38;5;241m=\u001b[39m y_col, listopc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m savecsv(file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/data_test_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(k) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(c) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     29\u001b[0m             data \u001b[38;5;241m=\u001b[39m x_p_v, col \u001b[38;5;241m=\u001b[39m x_col)\n",
      "\u001b[1;31mTypeError\u001b[0m: savecsv() got an unexpected keyword argument 'file_name'"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "# Validación cruzada\n",
    "kp = [3, 5, 10]\n",
    "for k in kp:\n",
    "    datas = cross_validation(data, k)\n",
    "    \n",
    "    # Save dataset in pickle\n",
    "    dataset_new = open('./data/dataset_f' + str(k) + '.pkl', 'wb')\n",
    "    pickle.dump(dataset_new, datas)\n",
    "    datas.close()\n",
    "    print('Completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e9b28fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save .csv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Guardar .csv\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mcreate_csv\u001b[49m(file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/data_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, data \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mtest_set\u001b[38;5;241m.\u001b[39mX_test, col_names \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m      5\u001b[0m create_csv(file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data/target_test.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, data \u001b[38;5;241m=\u001b[39m new_data\u001b[38;5;241m.\u001b[39mtest_set\u001b[38;5;241m.\u001b[39my_test, col_names \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;241m5\u001b[39m], list_opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Save .csv\n",
    "# Guardar .csv\n",
    "\n",
    "create_csv(file_name = \"./data/data_test.csv\", data = new_data.test_set.X_test, col_names = data[4])\n",
    "create_csv(file_name = \"./data/target_test.csv\", data = new_data.test_set.y_test, col_names = data[5], list_opt = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fb416",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
