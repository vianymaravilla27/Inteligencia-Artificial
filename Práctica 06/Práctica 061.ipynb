{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bac531c",
   "metadata": {},
   "source": [
    "## Práctica 6\n",
    "## Naive Bayes\n",
    "## Vianey Maravilla Pérez\n",
    "\n",
    "**Especificaciones:**\n",
    "\n",
    "- Los dataset utilizados para esta práctica serán *iris.csv* y *emails.csv*:\n",
    "\n",
    "**Dataset: Emails.csv***\n",
    "- La primera columna indica el id del correo\n",
    "- La última columna indica si el correo es spam o no\n",
    "- El resto de las columnas son las palabras más comunes en todos los correos\n",
    "\n",
    "**Dataset: Iris.csv**\n",
    "- Las primeras 4 columnas son las características de las instancias\n",
    "- La última columna es la clase\n",
    "\n",
    "**Dataset: Ambos datasets**\n",
    "- Carga el dataset\n",
    "- Crea un conjunto de entrenamiento del 70% de las instancias y el conjunto de pruebas con el 30% (set random_state=0)\n",
    "\n",
    "\n",
    "- Utilizando el conjunto de entrenamiento crea un conjunto de validación con 3 pliegues\n",
    "\n",
    "**Utilizando el conjunto de validación realiza lo siguiente con cada pliegue:**\n",
    "- Determina la exactitud de cada pliegue\n",
    "- Determina el promedio de exactitud de los 3 pliegues\n",
    "\n",
    "**Utilizando Multinomial con distribución normal para entrenar y prueba el modelo en cada pliegue:**\n",
    "- Determina la exactitud de cada pliegue\n",
    "- Determina el promedio de exactitud de los 3 pliegues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "bdbfb3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias que se requieren para la realización de la práctica\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8fcf26",
   "metadata": {},
   "source": [
    "# EMAILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "fca9b48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  \\\n",
      "0        Email 1    0   0    1    0    0   0    2    0    0  ...         0   \n",
      "1        Email 2    8  13   24    6    6   2  102    1   27  ...         0   \n",
      "2        Email 3    0   0    1    0    0   0    8    0    0  ...         0   \n",
      "3        Email 4    0   5   22    0    5   1   51    2   10  ...         0   \n",
      "4        Email 5    7   6   17    1    5   2   57    0    9  ...         0   \n",
      "...          ...  ...  ..  ...  ...  ...  ..  ...  ...  ...  ...       ...   \n",
      "5167  Email 5168    2   2    2    3    0   0   32    0    0  ...         0   \n",
      "5168  Email 5169   35  27   11    2    6   5  151    4    3  ...         0   \n",
      "5169  Email 5170    0   0    1    1    0   0   11    0    0  ...         0   \n",
      "5170  Email 5171    2   7    1    0    2   1   28    2    0  ...         0   \n",
      "5171  Email 5172   22  24    5    1    6   5  148    8    2  ...         0   \n",
      "\n",
      "      jay  valued  lay  infrastructure  military  allowing  ff  dry  \\\n",
      "0       0       0    0               0         0         0   0    0   \n",
      "1       0       0    0               0         0         0   1    0   \n",
      "2       0       0    0               0         0         0   0    0   \n",
      "3       0       0    0               0         0         0   0    0   \n",
      "4       0       0    0               0         0         0   1    0   \n",
      "...   ...     ...  ...             ...       ...       ...  ..  ...   \n",
      "5167    0       0    0               0         0         0   0    0   \n",
      "5168    0       0    0               0         0         0   1    0   \n",
      "5169    0       0    0               0         0         0   0    0   \n",
      "5170    0       0    0               0         0         0   1    0   \n",
      "5171    0       0    0               0         0         0   0    0   \n",
      "\n",
      "      Prediction  \n",
      "0              0  \n",
      "1              0  \n",
      "2              0  \n",
      "3              0  \n",
      "4              0  \n",
      "...          ...  \n",
      "5167           0  \n",
      "5168           0  \n",
      "5169           1  \n",
      "5170           1  \n",
      "5171           0  \n",
      "\n",
      "[5172 rows x 3002 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importamos el csv de EMAILS y lo visualizamos \n",
    "\n",
    "emails = pd.read_csv(r\"emails.csv\", sep = ',', engine = 'python')\n",
    "print (emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "77172fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos las variables X e Y con los siguientes valores\n",
    "\n",
    "X = emails.drop(emails.columns[[0, len(emails.columns)-1]], axis = 1).values\n",
    "y = emails['Prediction'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "b4e76b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5172, 3000)\n",
      "Index(['the', 'to', 'ect', 'and', 'for', 'of', 'a', 'you', 'hou', 'in',\n",
      "       ...\n",
      "       'enhancements', 'connevey', 'jay', 'valued', 'lay', 'infrastructure',\n",
      "       'military', 'allowing', 'ff', 'dry'],\n",
      "      dtype='object', length=3000)\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos lo siguiente con la variable de los nombres en X\n",
    "nombresX = emails.columns[1:(len(emails.columns)-1)]\n",
    "print(X.shape)\n",
    "print(nombresX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "c970ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la división del conjunto de entrenamiento y de prueba con sus respectivos porcentajes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, \n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d351711",
   "metadata": {},
   "source": [
    "# División de K pliegues\n",
    "\n",
    "**Mediante clases se hara las divisiones correspondientes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e73bccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacena una división extra de los respectivos datos de entrenamiento (validación)\n",
    "class validation: # validación por KFold\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test  = X_test\n",
    "        self.y_test  = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "53069d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacena los respetivos datos de prueba\n",
    "class test:\n",
    "    def __init__(self, X_test, y_test):\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "39d5d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almacena todas los datos divididos de entrenamiento con su división\n",
    "# Así mismo como los datos de prueba\n",
    "\n",
    "class dataset_v:\n",
    "    def __init__(self, validation, test):\n",
    "        self.validation = validation\n",
    "        self.test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ad645205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [1207 1208 1209 ... 3617 3618 3619] \n",
      " TEST: [   0    1    2 ... 1204 1205 1206]\n",
      "(2413, 3000)\n",
      "(1207, 3000)\n",
      "(2413,)\n",
      "(1207,)\n",
      "TRAIN: [   0    1    2 ... 3617 3618 3619] \n",
      " TEST: [1207 1208 1209 ... 2411 2412 2413]\n",
      "(2413, 3000)\n",
      "(1207, 3000)\n",
      "(2413,)\n",
      "(1207,)\n",
      "TRAIN: [   0    1    2 ... 2411 2412 2413] \n",
      " TEST: [2414 2415 2416 ... 3617 3618 3619]\n",
      "(2414, 3000)\n",
      "(1206, 3000)\n",
      "(2414,)\n",
      "(1206,)\n"
     ]
    }
   ],
   "source": [
    "# División de los datos con los pliegues\n",
    "\n",
    "# Definimos el número de pliegues y su lista de almacenamiento de los pliegues\n",
    "pliegues = 3\n",
    "validations = []\n",
    "kf = KFold(pliegues)\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    print(\"TRAIN:\", train_index, \"\\n\", \"TEST:\",\n",
    "          test_index)  # imprime los indices del dataset original que fueron elegidos como X_train y ahora, que seran usados como conjunto de train y de test\n",
    "    X_train_, X_test_ = X_train[train_index], X_train[test_index]\n",
    "    y_train_, y_test_ = y_train[train_index], y_train[test_index]\n",
    "    print(X_train_.shape)\n",
    "    print(X_test_.shape)\n",
    "    print(y_train_.shape)\n",
    "    print(y_test_.shape)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d385c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cada pliegue se agregara a una lista de validacion\n",
    "validations.append(validation(X_train_, y_train_, X_test_, y_test_))\n",
    "# Almacenamos los conjuntos originales de prueba de los datos\n",
    "tes_data = test(X_test, y_test)\n",
    "\n",
    "# Almacenamos X en pliegues y el dataset del conjunto de pruebas\n",
    "data_set = dataset_v(validations, tes_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "4d14b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial - Gauss \n",
    "\n",
    "modelos = ['Gauss', 'Multinomial']\n",
    "data_name =[]\n",
    "clasif = []\n",
    "promedios = []\n",
    "exactitudesPrueba = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78551c7b",
   "metadata": {},
   "source": [
    "# Gauss en 3 pliegues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d9a74036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "____________________________________\n",
      "\tGaussian Naive Bayes\n",
      "Pliegue: 2\n",
      "Prediccion: [0 0 1 ... 1 0 1] , (1206,)\n",
      "____________________________________\n",
      "Probabilidades sin función\n",
      "Clases: [0 1]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "____________________________________\n",
      "Accuracy: 0.9494195688225538\n",
      "Instancias predichas correctamente: 1145\n",
      "____________________________________\n",
      "\n",
      "Reporte de clasificación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96       852\n",
      "           1       0.89      0.94      0.92       354\n",
      "\n",
      "    accuracy                           0.95      1206\n",
      "   macro avg       0.93      0.95      0.94      1206\n",
      "weighted avg       0.95      0.95      0.95      1206\n",
      "\n",
      "____________________________________\n",
      "\n",
      "Matriz de confusión\n",
      "[[811  41]\n",
      " [ 20 334]]\n",
      "____________________________________\n",
      "[0.9494195688225538]\n",
      "____________________________________\n",
      "Promedio de exactitud de la predicción en los pliegues:0.9494195688225538\n"
     ]
    }
   ],
   "source": [
    "npliegue = 0\n",
    "exactitudes = []\n",
    "data = 'emails.csv'\n",
    "modelo = 'Gauss'\n",
    "for pliegue in validations: \n",
    "    pliegues = pliegues+1\n",
    "    clf = GaussianNB() \n",
    "    clf.fit(pliegue.X_train, pliegue.y_train) \n",
    "    predict_y = clf.predict(pliegue.X_test)\n",
    "    names = clf.classes_\n",
    "    print(names)\n",
    "    # names = names.tolist()\n",
    "    # Visualizaciones\n",
    "    print (\"____________________________________\")\n",
    "    print ('\\tGaussian Naive Bayes')\n",
    "    print(f'Pliegue: {n_pliegue}')\n",
    "    print('Prediccion:', predict_y, \",\", predict_y.shape)\n",
    "    print (\"____________________________________\")\n",
    "    print('Probabilidades sin función')\n",
    "    print(f'Clases: {names}')\n",
    "    print(clf.predict_proba(pliegue.X_test))\n",
    "    exactitud = accuracy_score(pliegue.y_test, predict_y)\n",
    "    exactitudes.append(exactitud)\n",
    "    print (\"____________________________________\")\n",
    "    print(f'Accuracy: {exactitud}')\n",
    "    print(f'Instancias predichas correctamente: {accuracy_score(pliegue.y_test, predict_y, normalize=False)}') \n",
    "    print (\"____________________________________\")\n",
    "    print('\\nReporte de clasificación')\n",
    "    print(classification_report(pliegue.y_test, predict_y))\n",
    "    print (\"____________________________________\")\n",
    "    print('\\nMatriz de confusión')\n",
    "    print(confusion_matrix(pliegue.y_test, predict_y, labels=clf.classes_))\n",
    "    print (\"____________________________________\")\n",
    "print(exactitudes)\n",
    "print (\"____________________________________\")\n",
    "promedioExac = sum (exactitudes) / len(exactitudes)\n",
    "promedios.append(promedioExac)\n",
    "data_name.append(data)\n",
    "clasif.append(modelo)\n",
    "print(f'Promedio de exactitud de la predicción en los pliegues:{promedioExac}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c88921a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "____________________________________\n",
      "\tMultinomial Naive Bayes\n",
      "Pliegue: 1\n",
      "Prediccion: [0 0 1 ... 1 0 1] , (1206,)\n",
      "____________________________________\n",
      "Probabilidades sin función\n",
      "Clases: [0 1]\n",
      "[[1.00000000e+000 1.36147654e-029]\n",
      " [1.00000000e+000 2.01630547e-072]\n",
      " [2.47409574e-007 9.99999753e-001]\n",
      " ...\n",
      " [1.99238367e-186 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.48863334e-048 1.00000000e+000]]\n",
      "____________________________________\n",
      "Accuracy: 0.9469320066334992\n",
      "Instancias predichas correctamente: 1142\n",
      "____________________________________\n",
      "\n",
      "Reporte de clasificación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       852\n",
      "           1       0.89      0.94      0.91       354\n",
      "\n",
      "    accuracy                           0.95      1206\n",
      "   macro avg       0.93      0.94      0.94      1206\n",
      "weighted avg       0.95      0.95      0.95      1206\n",
      "\n",
      "____________________________________\n",
      "\n",
      "Matriz de confusión\n",
      "[[810  42]\n",
      " [ 22 332]]\n",
      "____________________________________\n",
      "[0.9469320066334992]\n",
      "____________________________________\n",
      "Promedio de exactitud de la predicción en los pliegues:0.9469320066334992\n"
     ]
    }
   ],
   "source": [
    "pliegues = 3\n",
    "n_pliegue = 0\n",
    "exactitudes = []\n",
    "data = 'emails.csv'\n",
    "modelo = 'Multinomial'\n",
    "for pliegue in validations: \n",
    "    n_pliegue = n_pliegue+ 1\n",
    "    clf = MultinomialNB() \n",
    "    clf.fit(pliegue.X_train, pliegue.y_train) \n",
    "    predict_y = clf.predict(pliegue.X_test)\n",
    "    names = clf.classes_\n",
    "    print(names)\n",
    "    # names = names.tolist()\n",
    "    # Visualizaciones\n",
    "    print (\"____________________________________\")\n",
    "    print ('\\tMultinomial Naive Bayes')\n",
    "    print(f'Pliegue: {n_pliegue}')\n",
    "    print('Prediccion:', predict_y, \",\", predict_y.shape)\n",
    "    print (\"____________________________________\")\n",
    "    print('Probabilidades sin función')\n",
    "    print(f'Clases: {names}')\n",
    "    print(clf.predict_proba(pliegue.X_test))\n",
    "    exactitud = accuracy_score(pliegue.y_test, predict_y)\n",
    "    exactitudes.append(exactitud)\n",
    "    print (\"____________________________________\")\n",
    "    print(f'Accuracy: {exactitud}')\n",
    "    print(f'Instancias predichas correctamente: {accuracy_score(pliegue.y_test, predict_y, normalize=False)}') \n",
    "    print (\"____________________________________\")\n",
    "    print('\\nReporte de clasificación')\n",
    "    print(classification_report(pliegue.y_test, predict_y))\n",
    "    print (\"____________________________________\")\n",
    "    print('\\nMatriz de confusión')\n",
    "    print(confusion_matrix(pliegue.y_test, predict_y, labels=clf.classes_))\n",
    "    print (\"____________________________________\")\n",
    "print(exactitudes)\n",
    "print (\"____________________________________\")\n",
    "promedioExac = sum (exactitudes) / len(exactitudes)\n",
    "promedios.append(promedioExac)\n",
    "data_name.append(data)\n",
    "clasif.append(modelo)\n",
    "print(f'Promedio de exactitud de la predicción en los pliegues:{promedioExac}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a657b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos ahora una tabla con los datos\n",
    "datos ={'| Data Set |': data, '| Clasificador |': clasif , '| A.Prom |': promedios}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "7b3c8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metemos el modelo dentro de un dataframe\n",
    "tabla_modelo = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "1a3bc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Data Set | | Clasificador |  | A.Prom |\n",
      "0   emails.csv            Gauss    0.949420\n",
      "1   emails.csv      Multinomial    0.946932\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos\n",
    "print(tabla_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c6197",
   "metadata": {},
   "source": [
    "# Multinomial en los conjuntos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "3b4cd427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Gauss Naive Bayes\n",
      "emails.csv\n",
      "[0 1]\n",
      "____________________________________\n",
      "Prediccion: [1 0 0 ... 1 0 1] \n",
      "Total de Predicciones: 3620\n",
      "____________________________________\n",
      "Probabilidades sin función:\n",
      "Clases:[0 1]\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "____________________________________\n",
      "Accuracy: 0.9676795580110498\n",
      "Instancias predichas correctamente: 3503 de 3620\n",
      "____________________________________\n",
      "\n",
      "\t Reporte de clasificación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      2561\n",
      "           1       0.90      1.00      0.95      1059\n",
      "\n",
      "    accuracy                           0.97      3620\n",
      "   macro avg       0.95      0.98      0.96      3620\n",
      "weighted avg       0.97      0.97      0.97      3620\n",
      "\n",
      "\n",
      "\t Matriz de Confusión\n",
      "[[2447  114]\n",
      " [   3 1056]]\n",
      "\n",
      "\n",
      "\t Multinomial Naive Bayes\n",
      "emails.csv\n",
      "[0 1]\n",
      "____________________________________\n",
      "Prediccion: [1 0 0 ... 1 0 1] \n",
      "Total de Predicciones: 3620\n",
      "____________________________________\n",
      "Probabilidades sin función:\n",
      "Clases:[0 1]\n",
      "[[1.47344875e-025 1.00000000e+000]\n",
      " [1.00000000e+000 1.84863298e-024]\n",
      " [1.00000000e+000 4.53379644e-016]\n",
      " ...\n",
      " [9.16541422e-192 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.52145778e-051 1.00000000e+000]]\n",
      "____________________________________\n",
      "Accuracy: 0.9488950276243094\n",
      "Instancias predichas correctamente: 3435 de 3620\n",
      "____________________________________\n",
      "\n",
      "\t Reporte de clasificación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      2561\n",
      "           1       0.89      0.94      0.92      1059\n",
      "\n",
      "    accuracy                           0.95      3620\n",
      "   macro avg       0.93      0.95      0.94      3620\n",
      "weighted avg       0.95      0.95      0.95      3620\n",
      "\n",
      "\n",
      "\t Matriz de Confusión\n",
      "[[2435  126]\n",
      " [  59 1000]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Se aplica el modelo multinomial a los conjuntos de entrenamiento\n",
    "for modelo in modelos:\n",
    "    if modelo == 'Gauss':\n",
    "        clf = GaussianNB()\n",
    "        print('\\t Gauss Naive Bayes')\n",
    "    elif modelo == 'Multinomial':\n",
    "        clf = MultinomialNB()\n",
    "        print('\\t Multinomial Naive Bayes')\n",
    "    elif modelo == 'Bernoulli':\n",
    "        clf = BernoulliNB()\n",
    "        print('\\t Bernoulli Naive Bayes')\n",
    "    else:\n",
    "        print('No hay ese modelo por el momento, intente nuevamente')\n",
    "        break\n",
    "    \n",
    "    # Respectivas visualizaciones\n",
    "    print(data)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_y = clf.predict(X_train)\n",
    "    names = clf.classes_\n",
    "    print(names)\n",
    "    print (\"____________________________________\")\n",
    "    totalpredic = predict_y.shape[0]\n",
    "    print (\"Prediccion:\",predict_y, \"\\nTotal de Predicciones:\", totalpredic)\n",
    "    print (\"____________________________________\")\n",
    "    print(\"Probabilidades sin función:\")\n",
    "    print(f'Clases:{names}')\n",
    "    print(clf.predict_proba(X_train))\n",
    "    exactitud = accuracy_score(y_train, predict_y)\n",
    "    exactitudes.append(exactitud)\n",
    "    print (\"____________________________________\")\n",
    "    print(f'Accuracy: {exactitud}')\n",
    "    print(f'Instancias predichas correctamente: {accuracy_score(y_train, predict_y, normalize = False)} de {totalpredic}')\n",
    "    print (\"____________________________________\")\n",
    "    print('\\n\\t Reporte de clasificación')\n",
    "    print(classification_report(y_train, predict_y))\n",
    "    print('\\n\\t Matriz de Confusión')\n",
    "    matrix = confusion_matrix(y_train, predict_y, labels = clf.classes_)\n",
    "    print(matrix)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "1dbc4fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Gauss Naive Bayes\n",
      "[0 1]\n",
      "____________________________________\n",
      "Prediccion: [0 0 0 ... 0 1 0] \n",
      "Total de Predicciones: 1552\n",
      "____________________________________\n",
      "Probabilidades sin función:\n",
      "Clases:[0 1]\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n",
      "____________________________________\n",
      "Accuracy: 0.9484536082474226\n",
      "Instancias predichas correctamente: 1472 de 1552\n",
      "____________________________________\n",
      "\n",
      "\t Reporte de clasificación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96      1111\n",
      "           1       0.88      0.95      0.91       441\n",
      "\n",
      "    accuracy                           0.95      1552\n",
      "   macro avg       0.93      0.95      0.94      1552\n",
      "weighted avg       0.95      0.95      0.95      1552\n",
      "\n",
      "\n",
      "\t Matriz de Confusión\n",
      "[[1054   57]\n",
      " [  23  418]]\n",
      "\t Multinomial Naive Bayes\n",
      "[0 1]\n",
      "____________________________________\n",
      "Prediccion: [0 0 0 ... 0 1 0] \n",
      "Total de Predicciones: 1552\n",
      "____________________________________\n",
      "Probabilidades sin función:\n",
      "Clases:[0 1]\n",
      "[[1.00000000e+00 5.83437844e-20]\n",
      " [1.00000000e+00 6.63692242e-34]\n",
      " [1.00000000e+00 5.28140751e-83]\n",
      " ...\n",
      " [1.00000000e+00 2.05633691e-86]\n",
      " [3.87943174e-19 1.00000000e+00]\n",
      " [1.00000000e+00 3.32394238e-20]]\n",
      "____________________________________\n",
      "Accuracy: 0.9413659793814433\n",
      "Instancias predichas correctamente: 1461 de 1552\n",
      "____________________________________\n",
      "\n",
      "\t Reporte de clasificación\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1111\n",
      "           1       0.86      0.95      0.90       441\n",
      "\n",
      "    accuracy                           0.94      1552\n",
      "   macro avg       0.92      0.94      0.93      1552\n",
      "weighted avg       0.94      0.94      0.94      1552\n",
      "\n",
      "\n",
      "\t Matriz de Confusión\n",
      "[[1043   68]\n",
      " [  23  418]]\n"
     ]
    }
   ],
   "source": [
    "for modelo in modelos:\n",
    "    if modelo == 'Gauss':\n",
    "        clf = GaussianNB()\n",
    "        print('\\t Gauss Naive Bayes')\n",
    "    elif modelo == 'Multinomial':\n",
    "        clf = MultinomialNB()\n",
    "        print('\\t Multinomial Naive Bayes')\n",
    "    elif modelo == 'Bernoulli':\n",
    "        clf = BernoulliNB()\n",
    "        print('\\t Bernoulli Naive Bayes')\n",
    "    else:\n",
    "        print('No hay ese modelo por el momento, intente nuevamente')\n",
    "        break\n",
    "\n",
    "    # Respectivas visualizaciones\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict_y = clf.predict(X_test)\n",
    "    names = clf.classes_\n",
    "    print(names)\n",
    "    print (\"____________________________________\")\n",
    "    totalpredic = predict_y.shape[0]\n",
    "    print (\"Prediccion:\",predict_y, \"\\nTotal de Predicciones:\", totalpredic)\n",
    "    print (\"____________________________________\")\n",
    "    print(\"Probabilidades sin función:\")\n",
    "    print(f'Clases:{names}')\n",
    "    print(clf.predict_proba(X_test))\n",
    "    exactitud = accuracy_score(y_test, predict_y)\n",
    "    exactitudesPrueba.append(exactitud)\n",
    "    print (\"____________________________________\")\n",
    "    print(f'Accuracy: {exactitud}')\n",
    "    print(f'Instancias predichas correctamente: {accuracy_score(y_test, predict_y, normalize = False)} de {totalpredic}')\n",
    "    print (\"____________________________________\")\n",
    "    print('\\n\\t Reporte de clasificación')\n",
    "    print(classification_report(y_test, predict_y))\n",
    "    print('\\n\\t Matriz de Confusión')\n",
    "    print(confusion_matrix(y_test, predict_y, labels = clf.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "579720de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelamos ahora una tabla con los datos\n",
    "datos ={'| Data Set |': data, '| Clasificador |': clasif , '| A.Prom |': promedios, '| A. Prueba |': exactitudesPrueba}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "96b2e360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metemos el modelo dentro de un dataframe\n",
    "tabla_modelo = pd.DataFrame(datos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "47204cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Data Set | | Clasificador |  | A.Prom |  | A. Prueba |\n",
      "0   emails.csv            Gauss     0.94942       0.948454\n",
      "1   emails.csv            Gauss     0.94942       0.941366\n"
     ]
    }
   ],
   "source": [
    "# Visualizamos \n",
    "print(tabla_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3713fc5d",
   "metadata": {},
   "source": [
    "# IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "ab335b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width         species\n",
      "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
      "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
      "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
      "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
      "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
      "..            ...          ...           ...          ...             ...\n",
      "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
      "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
      "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
      "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
      "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Importamos el csv de iris y lo visualizamos \n",
    "iris = pd.read_csv(r\"iris.csv\", sep = ',', engine = 'python')\n",
    "print (iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "0bf070b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos las variables X e Y con los siguientes valores\n",
    "\n",
    "X = iris.drop(iris.columns[[0, len(iris.columns)-1]], axis = 1).values\n",
    "y = iris['species'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "9af72729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la división del conjunto de entrenamiento y de prueba con sus respectivos porcentajes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, shuffle = True, \n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "73948728",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [334]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m validation_iris \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      5\u001b[0m k1f \u001b[38;5;241m=\u001b[39m KFold\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[43mk1f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAIN:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTEST:\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m           test_index)  \u001b[38;5;66;03m# imprime los indices del dataset original que fueron elegidos como X_train y ahora, que seran usados como conjunto de train y de test\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     X_train_, X_test_ \u001b[38;5;241m=\u001b[39m X_train[train_index], X_train[test_index]\n",
      "\u001b[1;31mTypeError\u001b[0m: split() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "# División de los datos con los pliegues\n",
    "n_pliegues = 3\n",
    "# Almacenamiento de cada pliegue\n",
    "validation_iris = []\n",
    "k1f = KFold\n",
    "\n",
    "for train_index, test_index in k1f.split(X_train):\n",
    "    print(\"TRAIN:\", train_index, \"\\n\", \"TEST:\",\n",
    "          test_index)  # imprime los indices del dataset original que fueron elegidos como X_train y ahora, que seran usados como conjunto de train y de test\n",
    "    X_train_, X_test_ = X_train[train_index], X_train[test_index]\n",
    "    y_train_, y_test_ = y_train[train_index], y_train[test_index]\n",
    "    print(X_train_.shape)\n",
    "    print(X_test_.shape)\n",
    "    print(y_train_.shape)\n",
    "    print(y_test_.shape)\n",
    "    validation_iris.append(validation(X_train, y_train, X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "bc95bb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "____________________________________\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [328]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(exactitudes)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m____________________________________\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m promedioExac \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mexactitudes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexactitudes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m promedios\u001b[38;5;241m.\u001b[39mappend(promedioExac)\n\u001b[0;32m     38\u001b[0m data_name\u001b[38;5;241m.\u001b[39mappend(data)\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "n_pliegue = 0\n",
    "exactitudes = []\n",
    "data = 'iris.csv'\n",
    "modelo = 'Gauss'\n",
    "for pliegue in validation_iris: \n",
    "    n_pliegue = n_pliegue+1\n",
    "    clf = GaussianNB() \n",
    "    clf.fit(pliegue.X_train, pliegue.y_train) \n",
    "    predict_y = clf.predict(pliegue.X_test)\n",
    "    names = clf.classes_\n",
    "    print(names)\n",
    "    # names = names.tolist()\n",
    "    # Visualizaciones\n",
    "    print (\"____________________________________\")\n",
    "    print ('\\tGaussian Naive Bayes')\n",
    "    print(f'Pliegue: {n_pliegue}')\n",
    "    print('Prediccion:', predict_y, \",\", predict_y.shape)\n",
    "    print (\"____________________________________\")\n",
    "    print('Probabilidades sin función')\n",
    "    print(f'Clases: {names}')\n",
    "    print(clf.predict_proba(pliegue.X_test))\n",
    "    exactitud = accuracy_score(pliegue.y_test, predict_y)\n",
    "    exactitudes.append(exactitud)\n",
    "    print (\"____________________________________\")\n",
    "    print(f'Accuracy: {exactitud}')\n",
    "    print(f'Instancias predichas correctamente: {accuracy_score(pliegue.y_test, predict_y, normalize=False)}') \n",
    "    print (\"____________________________________\")\n",
    "    print('\\nReporte de clasificación')\n",
    "    print(classification_report(pliegue.y_test, predict_y))\n",
    "    print (\"____________________________________\")\n",
    "    print('\\nMatriz de confusión')\n",
    "    print(confusion_matrix(pliegue.y_test, predict_y, labels=clf.classes_))\n",
    "    print (\"____________________________________\")\n",
    "print(exactitudes)\n",
    "print (\"____________________________________\")\n",
    "promedioExac = sum (exactitudes) / len(exactitudes)\n",
    "promedios.append(promedioExac)\n",
    "data_name.append(data)\n",
    "clasif.append(modelo)\n",
    "print(f'Promedio de exactitud de la predicción en los pliegues:{promedioExac}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f82a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2828f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4261117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc2d8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
